{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to my Online Notebook.","text":"<p>I am currently taking the two classes that are the basis for this notebook so the content will expand as I learn. </p>"},{"location":"template/","title":"{{ title }}","text":"<p>Date: YYYY-MM-DD</p> <p>Topic: [Enter topic here]</p>"},{"location":"template/#overview","title":"Overview","text":"<p>[Write a brief summary or objectives of the lecture here.]</p>"},{"location":"template/#key-concepts","title":"Key Concepts","text":"<p>[Use bullet points or numbered lists]</p> <ul> <li>Concept 1</li> <li>Concept 2</li> <li>Concept 3</li> </ul>"},{"location":"template/#important-equations","title":"Important Equations","text":"<p>[Use display math for equations. Never escape <code>_</code> or <code>^</code> in math mode.]</p> \\[ \\text{Example: } F = m a \\] \\[ E_x(\\vec{r}, t) = R(\\vec{r}) e^{-i \\omega t} \\] <p>[Add more equations as needed]</p>"},{"location":"template/#derivations-worked-examples","title":"Derivations / Worked Examples","text":"<p>[Use display math for any multi-line derivations]</p> \\[ \\nabla \\times (\\nabla \\times \\vec{E}) = -\\frac{\\partial}{\\partial t} (\\nabla \\times \\vec{B}) \\] \\[ \\nabla (\\nabla \\cdot \\vec{E}) - \\nabla^2 \\vec{E} = -\\mu_0 \\epsilon_0 \\frac{\\partial^2 \\vec{E}}{\\partial t^2} \\] <p>[Step-by-step derivations]</p>"},{"location":"template/#notes-observations","title":"Notes / Observations","text":"<p>[Include any side notes, physical intuition, or references here.]</p> <ul> <li>Note 1</li> <li>Note 2</li> </ul>"},{"location":"template/#references-resources","title":"References / Resources","text":"<p>[Include textbooks, papers, or lecture slides]</p> <ol> <li>Textbook A</li> <li>Paper B</li> <li>Online resource C</li> </ol>"},{"location":"Optics/","title":"PHYS 5381 Spectial Topics: Optics","text":"<p>Instructor: Dr. Hilton Term Spring 2026</p>"},{"location":"Optics/#lectures","title":"Lectures","text":""},{"location":"Optics/#geometrical-optics","title":"Geometrical Optics","text":"<ul> <li>Lecture 1</li> <li>Lecture 2</li> </ul>"},{"location":"Optics/#homework-assignments","title":"Homework Assignments","text":"<ul> <li>HW1</li> <li>HW2</li> </ul>"},{"location":"Optics/Homework/Optics_HW1/","title":"Homework 1:","text":"<p>Staring with Maxwell's equations in matter and in the time-domain, Fourier transform these equations and rewrite them in the frequency domain.</p>"},{"location":"Optics/Homework/Optics_HW1/#solution","title":"Solution","text":"<p>The fourier transform is defined as:</p> \\[ \\tilde{F}[f(t)] = F(\\omega) = \\int_{-\\infty}^{\\infty} f(t) e^{-i \\omega t} dt\\]"},{"location":"Optics/Homework/Optics_HW1/#gauss-law-for-electricity-in-matter","title":"Gauss' Law for Electricity in matter:","text":"\\[\\vec{\\nabla} \\cdot \\vec{D}(\\vec{r},t) = \\rho_{f}(\\vec{r},t)\\] <p>Taking the Fourier transform:</p> \\[ \\int_{-\\infty}^{\\infty} \\vec{\\nabla} \\cdot \\vec{D}(\\vec{r},t) e^{-i \\omega t} dt = \\int_{-\\infty}^{\\infty} \\rho_{f}(\\vec{r},t) e^{-i \\omega t} dt \\] <p>Bringing the divergence operator outside the integral (as it only acts on spatial coordinates):</p> \\[ \\vec{\\nabla} \\cdot \\int_{-\\infty}^{\\infty} \\vec{D}(\\vec{r},t) e^{-i \\omega t} dt = \\int_{-\\infty}^{\\infty} \\rho_{f}(\\vec{r},t) e^{-i \\omega t} dt \\] <p>Simplifying the Fourier transforms:</p> \\[\\vec{\\nabla} \\cdot \\tilde{D}(\\vec{r},\\omega) = \\tilde{\\rho}_{f}(\\vec{r},\\omega)\\]"},{"location":"Optics/Homework/Optics_HW1/#gauss-law-for-magnetism-in-matter","title":"Gauss' Law for Magnetism in matter:","text":"\\[ \\vec{\\nabla} \\cdot \\vec{B}(\\vec{r},t) = 0 \\] <p>Taking the Fourier transform:</p> \\[\\int_{-\\infty}^{\\infty} \\vec{\\nabla} \\cdot \\vec{B}(\\vec{r},t) e^{-i \\omega t} dt = 0 \\] <p>Bringing the divergence operator outside the integral:</p> \\[  \\vec{\\nabla} \\cdot \\int_{-\\infty}^{\\infty} \\vec{B}(\\vec{r},t) e^{-i \\omega t} dt = 0 \\] <p>Simplifying the Fourier transform:</p> \\[ \\vec{\\nabla} \\cdot \\tilde{B}(\\vec{r},\\omega) = 0 \\]"},{"location":"Optics/Homework/Optics_HW1/#faradays-law-in-matter","title":"Faraday's Law in matter:","text":"\\[ \\vec{\\nabla} \\times \\vec{E}(\\vec{r},t) = - \\frac{\\partial \\vec{B}(\\vec{r},t)}{\\partial t} \\] <p>Taking the Fourier transform:</p> \\[ \\int_{-\\infty}^{\\infty} \\vec{\\nabla} \\times \\vec{E}(\\vec{r},t) e^{-i \\omega t} dt = - \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{B}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt  \\] <p>Bringing the curl outside the integral:</p> \\[  \\vec{\\nabla} \\times \\int_{-\\infty}^{\\infty} \\vec{E}(\\vec{r},t) e^{-i \\omega t} dt = - \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{B}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt \\] <p>Simplifying the Fourier transform on the left side:</p> \\[ \\vec{\\nabla} \\times \\tilde{E}(\\vec{r},\\omega) = - \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{B}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt \\] <p>Using integration by parts on the right side:</p> \\[ u = e^{-i \\omega t} \\quad dv = \\frac{\\partial \\vec{B}(\\vec{r},t)}{\\partial t} dt \\] \\[ du = -i \\omega e^{-i \\omega t} dt \\quad v = \\vec{B}(\\vec{r},t) \\] \\[ \\int u \\, dv = uv - \\int v \\, du \\] \\[ \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{B}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt = \\left[ \\vec{B}(\\vec{r},t) e^{-i \\omega t} \\right]_{-\\infty}^{\\infty} + i \\omega \\int_{-\\infty}^{\\infty} \\vec{B}(\\vec{r},t) e^{-i \\omega t} dt \\] <p>Assuming the special case where \\(\\rho = 0\\) and \\(\\vec{J} = 0\\) as we did in class lets us simplify the differential:</p> \\[ -\\frac{\\partial \\vec{B}}{\\partial t} = \\nabla \\times \\vec{E} \\] \\[ \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{B}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt = i \\omega \\tilde{B}(\\vec{r},\\omega) \\] <p>Resulting in:</p> \\[\\vec{\\nabla} \\times \\tilde{E}(\\vec{r},\\omega) = - i \\omega \\tilde{B}(\\vec{r},\\omega)\\]"},{"location":"Optics/Homework/Optics_HW1/#ampere-maxwell-law-in-matter","title":"Ampere-Maxwell Law in matter:","text":"\\[ \\vec{\\nabla} \\times \\vec{H}(\\vec{r},t) = \\vec{J}_{f}(\\vec{r},t) + \\frac{\\partial \\vec{D}(\\vec{r},t)}{\\partial t} \\] <p>Taking the Fourier transform:</p> \\[ \\int_{-\\infty}^{\\infty} \\vec{\\nabla} \\times \\vec{H}(\\vec{r},t) e^{-i \\omega t} dt = \\int_{-\\infty}^{\\infty} \\vec{J}_{f}(\\vec{r},t) e^{-i \\omega t} dt + \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{D}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt \\] <p>Bringing the curl operator outside the integral:</p> \\[ \\vec{\\nabla} \\times \\int_{-\\infty}^{\\infty} \\vec{H}(\\vec{r},t) e^{-i \\omega t} dt = \\int_{-\\infty}^{\\infty} \\vec{J}_{f}(\\vec{r},t) e^{-i \\omega t} dt + \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{D}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt \\] <p>Simplifying the Fourier transforms on the left side and the first term on the right side:</p> \\[ \\vec{\\nabla} \\times \\tilde{H}(\\vec{r},\\omega) = \\tilde{J}_{f}(\\vec{r},\\omega) + \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{D}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt \\] <p>Using integration by parts on the last term:</p> \\[ u = e^{-i \\omega t} \\quad dv = \\frac{\\partial \\vec{D}(\\vec{r},t)}{\\partial t} dt  \\] \\[  du = -i \\omega e^{-i \\omega t} dt \\quad v = \\vec{D}(\\vec{r},t) \\] \\[  \\int u \\, dv = uv - \\int v \\, du  \\] \\[ \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{D}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt = \\left[ \\vec{D}(\\vec{r},t) e^{-i \\omega t} \\right]_{-\\infty}^{\\infty} + i \\omega \\int_{-\\infty}^{\\infty} \\vec{D}(\\vec{r},t) e^{-i \\omega t} dt \\] <p>I have not taken enough physics to know if this is valid but from what I have read in literature it is a standard assumption to say \\(\\vec{D}(\\vec{r},t)\\) goes to 0 and +/- \\(\\infty\\). This would cause the extra \\([\\vec{D}(\\vec{r},t)\\exp{[-i \\omega t]}]\\) term to go away leaving in integration resul:. </p> \\[ \\int_{-\\infty}^{\\infty} \\frac{\\partial \\vec{D}(\\vec{r},t)}{\\partial t} e^{-i \\omega t} dt = i \\omega \\tilde{D}(\\vec{r},\\omega) \\] <p>Resulting in:</p> \\[  \\vec{\\nabla} \\times \\tilde{H}(\\vec{r},\\omega) = \\tilde{J}_{f}(\\vec{r},\\omega) + i \\omega \\tilde{D}(\\vec{r},\\omega)  \\]"},{"location":"Optics/Homework/Optics_HW2/","title":"Homework 2","text":"<p>Staring with Faraday's Law in the Frequency domain, derive Helmholtz's equation for \\(\\vec{E}\\) defining all new quantities that you introduce (e.g.\\(\\vec{k}\\)) and also any simplifying assumptions that you need to make to arrive at this equation.</p> <p>Helmholtz's equation:</p> \\[ \\nabla^2 \\vec{E} + k^2 \\vec{E} = 0 \\]"},{"location":"Optics/Homework/Optics_HW2/#solution","title":"Solution:","text":"<p>Beginning with Faradays Law in the frequency domain:</p> \\[ \\nabla \\times \\tilde{E} = -i \\omega \\tilde{B} \\] <p>We can take the curl of both sides:</p> \\[ \\nabla \\times [\\nabla \\times \\tilde{E}] = \\nabla \\times [-i \\omega \\tilde{B}] \\] <p>Working on the left hand side we can use the vector triple product to get:</p> \\[ \\nabla(\\nabla \\cdot \\tilde{E}) - \\nabla^2 \\tilde{E} = \\nabla \\times [-i \\omega \\tilde{B}] \\] <p>Using the same assumptions we made in class \\(\\rho = 0\\)  and \\(\\vec{J} = 0\\) allows us set  \\(\\nabla \\cdot \\tilde{E} = 0\\)  We can then see that the diivergence of 0 is 0 making the entire first term vanish leaving </p> \\[ -\\nabla^2 \\tilde{E} = \\nabla \\times [-i \\omega \\tilde{B}] \\] <p>i and \\(\\omega\\) can be brought out of the cross product and we are left with </p> \\[-\\nabla^2 \\tilde{E} = i \\omega[\\nabla \\times \\tilde{B}]\\] <p>we know that</p> \\[ \\nabla \\times \\vec{B} = \\mu_0 \\vec{J} + \\mu_0 \\epsilon_0 \\vec{E} \\] <p>So inputting this results in </p> \\[ -\\nabla^2 \\tilde{E} = i \\omega[\\mu_0 \\vec{J} + \\mu_0 \\epsilon_0 \\vec{E}] \\] <p>With the assumptions made earlier, \\(\\vec{J} = 0\\) so that term vanishes leaving</p> \\[ -\\nabla^2 \\tilde{E} = i \\omega[\\ \\mu_0 \\epsilon_0 \\vec{E}] \\] <p>We can subtract the right hand side from both sides of the equation and then multiply by -1 to reach:</p> \\[ \\nabla^2 \\tilde{E} + i \\omega[\\ \\mu_0 \\epsilon_0 \\vec{E}] = 0 \\] <p>Then, finally, to reach the desired form we set the constants in the second term equal to another constant, \\(k^2\\) which means </p> \\[ k = \\sqrt{i \\omega \\mu_0 \\epsilon_0}\\] <p>leaving us with the desired result. </p> \\[ \\nabla^2 \\tilde{E} + k^2 \\tilde{E} = 0 \\]"},{"location":"Optics/Lectures/Opt_01_20_26/","title":"Lecture 1","text":"<p>Introduction to the course and beginning material.</p> <p>Beginning with Geometrical optics, we should remember the following from Physics 2:</p>"},{"location":"Optics/Lectures/Opt_01_20_26/#maxwells-equations-in-vacuum-integral-form","title":"Maxwell's Equations in Vacuum (Integral Form)","text":"\\[\\oint \\vec{E} \\cdot d\\vec{A} = \\frac{q_{enc}}{\\epsilon_0}\\] \\[\\int_s \\vec{B} \\cdot d\\vec{A} = 0 \\] \\[\\oint \\vec{E} \\times d\\vec{l} = -\\frac{d\\Phi_B}{dt}\\] \\[\\oint \\vec{B} \\times d\\vec{l} = \\mu_0 I + \\frac{d \\Phi_E}{dt}\\] <p>\\(\\Phi_E\\) is a time-dependent electric field.</p>"},{"location":"Optics/Lectures/Opt_01_20_26/#maxwells-equations-in-vacuum-differential-form","title":"Maxwell's Equations in Vacuum (Differential Form)","text":"\\[\\nabla \\cdot \\vec{E} = \\frac{\\rho}{\\epsilon_0}\\] \\[\\nabla \\cdot \\vec{B} = 0\\] \\[\\nabla \\times \\vec{E} = -\\frac{\\partial \\vec{B}}{\\partial t}\\] \\[\\nabla \\times \\vec{B} = \\mu_0 \\vec{J} + \\mu_0 \\epsilon_0 \\frac{\\partial \\vec{E}}{\\partial t}\\]"},{"location":"Optics/Lectures/Opt_01_20_26/#maxwells-equations-in-matter","title":"Maxwell's Equations in Matter","text":"<p>A constant electric field \\(\\vec{E}\\) will induce a polarization \\(\\vec{P}\\). The measured displacement vector is:</p> \\[\\vec{D} = \\epsilon_0 \\vec{E} + \\vec{P}\\] <p>Similarly, for magnetic fields:</p> \\[\\vec{B} = \\mu_0 \\vec{H} + \\vec{M}\\] <p>Different books/resources may refer to \\(\\vec{H}\\) and \\(\\vec{B}\\) interchangeably; we will stick with \\(B\\) and \\(H\\).</p> \\[\\nabla \\cdot \\vec{D} = \\rho_{free}\\] \\[\\nabla \\cdot \\vec{B} = 0\\] \\[\\nabla \\times \\vec{E} = -\\frac{\\partial \\vec{B}}{\\partial t}\\] \\[\\nabla \\times \\vec{H} = \\vec{J}_{free} + \\frac{\\partial \\vec{D}}{\\partial t}\\]"},{"location":"Optics/Lectures/Opt_01_20_26/#constructing-wave-equations-in-vacuum","title":"Constructing Wave Equations in Vacuum","text":"<p>Special case: \\(\\rho = 0\\) (no free charge), \\(\\vec{J} = 0\\) (no current)</p> \\[\\nabla \\cdot \\vec{E} = 0\\] \\[\\nabla \\cdot \\vec{B} = 0\\] \\[\\nabla \\times \\vec{E} = -\\frac{\\partial \\vec{B}}{\\partial t}\\] \\[\\nabla \\times \\vec{B} = \\mu_0 \\epsilon_0 \\frac{\\partial \\vec{E}}{\\partial t}\\] <p>Taking the curl of \\(\\nabla \\times \\vec{E}\\):</p> \\[\\nabla \\times (\\nabla \\times \\vec{E}) = -\\frac{\\partial}{\\partial t} (\\nabla \\times \\vec{B})\\] <p>Using the vector identity \\(\\nabla \\times (\\nabla \\times \\vec{E}) = \\nabla (\\nabla \\cdot \\vec{E}) - \\nabla^2 \\vec{E}\\):</p> \\[\\nabla (\\nabla \\cdot \\vec{E}) - \\nabla^2 \\vec{E} = -\\mu_0 \\epsilon_0 \\frac{\\partial^2 \\vec{E}}{\\partial t^2}\\] <p>Since \\(\\nabla \\cdot \\vec{E} = 0\\):</p> \\[\\nabla^2 \\vec{E} = \\mu_0 \\epsilon_0 \\frac{\\partial^2 \\vec{E}}{\\partial t^2}\\] <p>Similarly for the magnetic field:</p> \\[\\nabla^2 \\vec{B} = \\mu_0 \\epsilon_0 \\frac{\\partial^2 \\vec{B}}{\\partial t^2}\\] <p>Linear Polarization:</p> \\[\\vec{E} = E_x \\hat{x}, \\quad \\vec{B} = B_y \\hat{y}, \\quad \\vec{k} = k_0 \\hat{z}\\] <p>Assume separation of variables:</p> \\[E_x(\\vec{r}, t) = R(\\vec{r}) T(t)\\] <p>Plugging into the wave equation:</p> \\[\\nabla^2 [R(\\vec{r}) T(t)] = \\mu_0 \\epsilon_0 \\frac{d^2}{dt^2} [R(\\vec{r}) T(t)]\\] <p>Since \\(\\nabla^2\\) acts only on spatial variables and \\(d^2/dt^2\\) acts only on time:</p> \\[T(t) \\nabla^2 R(\\vec{r}) = \\mu_0 \\epsilon_0 R(\\vec{r}) \\frac{d^2 T(t)}{dt^2}\\] <p>Divide both sides by \\(R(\\vec{r}) T(t)\\):</p> \\[\\frac{\\nabla^2 R(\\vec{r})}{R(\\vec{r})} + \\mu_0 \\epsilon_0 \\frac{1}{T(t)} \\frac{d^2 T(t)}{dt^2} = 0\\] <p>We see that there is are both time and space dependent parts of our equation which must sum to 0 so they are equal and opposite and can be set to some constant, say \\(-k^2\\). </p> \\[ -\\frac{\\nabla^2 R(\\vec{r})}{R(\\vec{r})} = \\mu_0 \\epsilon_0 \\frac{1}{T(t)} \\frac{d^2 T(t)}{dt^2} = -k^2 \\] <p>We will treat the spacially dependent portion later but for now we will be looking at the time dependent equation:</p> \\[\\frac{d^2 T(t)}{dt^2} + \\frac{k^2}{\\mu_0 \\epsilon_0} T(t) = 0\\] <p>Letting \\(c = 1/\\sqrt{\\mu_0 \\epsilon_0}\\), we have:</p> \\[\\frac{d^2 T(t)}{dt^2} + \\omega^2 T(t) = 0, \\quad \\omega = \\frac{k}{c}\\] <p>Solutions:</p> \\[T(t) = A \\cos(\\omega t) + B \\sin(\\omega t) \\quad \\text{or} \\quad T(t) = C e^{i \\omega t} + D e^{-i \\omega t}\\] <p>We usually adopt the convention:</p> \\[T(t) = D e^{-i \\omega t}\\] <p>Monochromatic electric field:</p> \\[E_x(\\vec{r}, t) = R(\\vec{r}) e^{-i \\omega t} = R(\\vec{r}) e^{-i 2\\pi \\nu t}\\] <p>Polychromatic light:</p> \\[E_x(\\vec{r}, t) = \\sum_\\ell D_\\ell(\\nu) e^{-i 2\\pi \\nu t} = \\int_{-\\infty}^{\\infty} D(\\nu) e^{-i 2\\pi \\nu t} d\\nu\\] <p>Frequency-domain representation:</p> \\[\\tilde{E}_x(\\vec{r}, \\nu) = \\int_{-\\infty}^{\\infty} E_x(\\vec{r}, t) e^{i 2\\pi \\nu t} dt\\]"},{"location":"Optics/Lectures/Opt_01_22_26/","title":"Lecture 2","text":"<p>In this class we will assume that Maxwells Equations are linear and that if we want to work with polychromatic light we can break it into individual wavelengths and then treat each individually, summing at the end to get our total result. This breaks down in special cases that we may treat later</p>"},{"location":"Optics/Lectures/Opt_01_22_26/#space-dependent-equation-from-last-time","title":"Space Dependent Equation from Last Time","text":"<p>In the previous lecture, we had the intermediate result:</p> \\[\\frac{\\nabla^2 R(\\vec{r})}{R(\\vec{r})} + \\mu_0 \\epsilon_0 \\frac{1}{T(t)} \\frac{d^2 T(t)}{dt^2} = 0\\] <p>We treated the time dependent portion previously and will now move into solving the space dependent equation:</p> \\[ \\nabla^2 R + k^2 R = 0\\] <p>First we will define the vector \\(\\vec{k}\\) as being \\(\\hat{x} k_x + \\hat{y} k^y + \\hat{z} k_z\\). Using this vector and expanding the laplacian we get:</p> \\[ [\\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2} +\\frac{\\partial^2}{\\partial z^2}]R + [k_x^2 + k_y^2 +k_z^2]R = 0 \\] <p>We can combine each of the x terms together and do the same for y and z to get:</p> \\[ [\\frac{\\partial^2 R}{\\partial x^2} + k_x^2R] + [\\frac{\\partial^2 R}{\\partial y^2} + k_y^2 R] + [\\frac{\\partial^2 R}{\\partial z^2} + k_z^2R] = 0 \\] <p>Here we have two directions to choose from in our solution of R, our determination of R will depend on if we are treating the electic field as plane waves (option 1) which is the foundation for geometrial optics or as spherical waves (option 2) which is the foundaton for wave optics. </p>"},{"location":"Optics/Lectures/Opt_01_22_26/#option-1-geometrical-optics","title":"Option 1 (Geometrical Optics):","text":"\\[ R(r) = [A e^{i k_x x} + B e^{-i k_x x}] \\cdot [C e^{i k_y y} + C e^{-i k_y y}] \\cdot [D e^{i k_z z} + E e^{-i k_z z}] \\]"},{"location":"Optics/Lectures/Opt_01_22_26/#option-2-wave-optics","title":"Option 2 (Wave Optics):","text":"\\[ R(r) = \\frac{G e^{i \\vec{k}r}}{r} + \\frac{H e^{-i \\vec{k}r}}{r} \\] <p>For now we will be wokring in the domain of option 1. Our vector \\(\\vec{k}\\) is the \"ray vector\" and we will largly be focused on tracing this vector and its behavior through optical systems. </p> <p>When geometrial optics fail as a result of things like edge effects, we need a more comprehensive tool to solve problems. This is option two for wave optics which we will work with later. When this breaks down and we need to deal with individual photons this is the realm of quantum optics but we wont reach that point this class. </p>"},{"location":"Optics/Lectures/Opt_01_22_26/#ray-tracing","title":"Ray Tracing","text":"<p>How do I move \\(\\vec{k}\\) around in space?</p> <p>We will explore this with the following example:</p> <p></p> <p>The variables are as follows: - \\(n_i\\) refractive index of region i - \\(\\mathcal{v}_i\\) speed of light in region i - \\(\\theta_{i}\\) angle that the vector i makes with interface normal. </p> <p>First we need to figure out the lenght of the vector from A to the interface I:</p> \\[ L_{AI} = \\sqrt{(\\omega - z_0)^2 + (H - x)^2} \\] <p>then we will figure out the lenght from I to B:</p> \\[ L_{IB} = \\sqrt{(x)^2+(z_0)^2} \\] <p>Now we know the lenght and the speed of light in each medium so we can find the time, \\(\\tau\\), the vector takes to get from A to I and then from I to B.</p> \\[ \\tau_{AI} = \\frac{\\sqrt{(\\omega - z_0)^2 + (H - x)^2}}{\\mathcal{v_1}} \\] \\[ \\tau_{IB} = \\frac{\\sqrt{(x)^2+(z_0)^2}}{\\mathcal{v_2}} \\] <p>We sum these to get the total time:</p> \\[ \\tau_{AIB} = \\frac{\\sqrt{(\\omega - z_0)^2 + (H - x)^2}}{\\mathcal{v_1}} + \\frac{\\sqrt{(x)^2+(z_0)^2}}{\\mathcal{v_2}} \\] <p>Fermats principle of least time states that this quantity will be minimized so we can find the minimum by taking the derivative and then setting it equal to zero and looking at the result. </p> \\[ \\frac{d \\tau}{dx} = \\frac{1}{2} \\left( \\frac{-2 (H-x)}{\\mathcal{v_1}\\sqrt{(w-z_0)^2 + (H-x)^2}} \\right) + \\frac{1}{2} \\left( \\frac{2x}{\\mathcal{v_2}\\sqrt{x^2+z_0^2}}\\right) = 0 \\] <p>This can be simplified to:</p> \\[ \\frac{d \\tau}{dx} =  \\left( \\frac{(H-x)}{\\mathcal{v_1}\\sqrt{(w-z_0)^2 + (H-x)^2}} \\right) + \\left( \\frac{x}{\\mathcal{v_2}\\sqrt{x^2+z_0^2}}\\right) = 0 \\] <p>we can recognize</p> \\[  \\left( \\frac{(H-x)}{\\sqrt{(w-z_0)^2 + (H-x)^2}} \\right) = \\sin{\\theta_1} \\] \\[ \\left( \\frac{x}{\\sqrt{x^2+z_0^2}}\\right) = \\sin{\\theta_2} \\] <p>we can write \\(\\mathcal{v}_1\\) and \\(\\mathcal{v}_2\\) in terms of the speed of light \\(\\mathcal{v} = \\frac{c}{n}\\) to obtain:</p> \\[ -\\frac{n_1}{c}\\sin{\\theta_1} +  \\frac{n_2}{c}\\sin{\\theta_2} = 0 \\] <p>Then we can multiply by c on both sides and subtract across one term whigh gives us the familiar result of Snells law:</p> \\[ n_1 \\sin{\\theta_1} = n_2 \\sin{\\theta_2} \\] <p>In the homework we will also derive Snells law from maxwells equaions using phase matching. </p>"},{"location":"Optics/Lectures/Opt_01_22_26/#this-the-the-basic-result-we-want-to-use-for-mirrors-and-lenses-where-we-trace-the-ray-vector-veck-through-the-system","title":"This the the basic result we want to use for mirrors and lenses where we trace the ray vector, \\(\\vec{k}\\) through the system.","text":""},{"location":"Optics/Lectures/Opt_01_22_26/#optical-design","title":"Optical Design","text":"<p>In this example we want to design the focal lengh of an optical system. </p> <p></p> <p>There are two approches we can take - q u (\"exact\") ray tracing - y nu (\"Paraxial Approximation\") ray tracing</p> <p>qu is far less common and we will mostly deal with YNU ray tracing. </p> <p>Our object (the arrow) has a continuum of vecotrs coming off each point in many directions so we need a way to distingush our desired vector, \\(\\vec{f}\\) from all others.</p>"},{"location":"Optics/Lectures/Opt_01_22_26/#q-u-ray-tracing","title":"q u Ray Tracing","text":"<p>In q u we distingush \\(\\vec{f}\\) using the height off the central axis (q) and the angle that \\(\\vec{f}\\) makes with the central axis (u)</p> \\[ \\vec{f}_1 =  \\begin{pmatrix} q_1 \\\\ u_1 \\end{pmatrix} \\] <p>This type of ray tracing includes lots of trigonomerty. </p>"},{"location":"Optics/Lectures/Opt_01_22_26/#y-nu-ray-tracing","title":"y nu Ray Tracing","text":"<p>y nu ray tracing uses the height of the ray off the central axis (y) and the refractive index multiplied by the angle the vector makes with the central axis (nu) to distinguish the desired vector. </p> <p>y nu is called a paraxial approximation because we use the small angle approximations for sine and tangent</p> \\[ \\tan{\\theta} \\approx \\theta \\] \\[ \\sin{\\theta} \\approx \\theta \\] <p>In the taylor expansion for sin and theta this approximation holds for small angles. The taylor expansion only contians terms of first, third, fifth, ... order and this is where the terms \"first order correction\", \"third order correction\", ect. origionate from.</p> <p>now we have a ray</p> \\[ \\vec{f_1} =  \\begin{pmatrix} y_1 \\\\ n_1 u_1 \\end{pmatrix} \\] <p>Example: We want to trace a vector \\(\\vec{f}_1\\) to \\(\\vec{f}_2\\) some distance d away.</p> <p>Image Here</p> <p>Our first vector has a height of \\(y_1\\) and the image \\(y_2 = y_1 + \\Delta y\\)</p> \\[ \\Delta y = d \\tan{\\theta \\approx d\\theta} (\\theta = n_1 u_1) \\] \\[ \\Delta y = \\frac{d (n_1 u_1)}{n_1} \\] \\[ y_2 = y_1 + \\frac{d (n_1 u_1)}{n_1} \\] \\[ \\vec{f}_2 =  \\begin{pmatrix} y_2 \\\\ n_2 u_2 \\end{pmatrix} \\] <p>Becasue the vetor continues in a straight line, the angles that vectors \\(\\vec{f}_1\\) and \\(\\vec{f}_2\\) make with the central axis will be the same:</p> \\[ n_1 u_1 = n_2 u_2 \\] <p>Because vectors \\(\\vec{f}_1\\) and \\(\\vec{f}_2\\) are 2x1 matricies, we need a 2x2 matrix to get from one to the other:</p> \\[ \\begin{pmatrix} y_2 \\\\ n_2 u_2 \\end{pmatrix} = \\begin{pmatrix} A &amp; B \\\\ C &amp; D \\end{pmatrix} \\begin{pmatrix} y_1 \\\\ n_1 u_1 \\end{pmatrix} \\] <p>Using matrix multiplication, we obtain</p> \\[ \\begin{pmatrix} y_2 \\\\ n_2 u_2 \\end{pmatrix} = \\begin{pmatrix} A y_1 + B n_1 u_1 \\\\ C y_1 + D n_1 u_1 \\end{pmatrix} \\] <p>Now we can determine A, B, C and D using the two equations: \\(y_2 = y_1 + \\frac{d}{n_1}(n_1 u_1)\\) and \\(n_1 u_1 = n_2 u_2\\)</p> <p>We can see clearly that \\(A = 1\\), \\(B= \\frac{d}{n}\\), \\(C=0\\), and \\(D = 1\\).</p> <p>This gives us the final result that to perform free space propogation of our ray in a medium with refractive index \\(n_1\\) we need to multiply \\(\\vec{f}\\) by the matrix</p> \\[ \\bar{m} =  \\begin{pmatrix} 1 &amp; \\frac{d}{n_1} \\\\ 0 &amp; 1 \\end{pmatrix} \\]"},{"location":"Statistical_Mechanics/","title":"Chem 5320 - Statistical Mechanics","text":"<p>Instructor: Dr. Shuford Term Spring 2026</p>"},{"location":"Statistical_Mechanics/#lectures","title":"Lectures","text":""},{"location":"Statistical_Mechanics/#introductionreview","title":"Introduction/Review","text":"<ul> <li>Lecture 1</li> <li>Lecture 2</li> </ul>"},{"location":"Statistical_Mechanics/#homework-assignments","title":"Homework Assignments","text":"<ul> <li>HW1</li> </ul>"},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/","title":"Lecture 1","text":""},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/#introduction-to-the-course-and-beginning-material","title":"Introduction to the course and beginning material","text":"<p>In this course we will mostly cover statistical thermodynamics (equilibrium statistical mechanics). Non-equilibrium statistical mechanics may be covered briefly towards the end of the course if time permits.</p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/#review-of-quantum-mechanics","title":"Review of Quantum Mechanics","text":"<p>Before starting statistical mechanics, we review quantum mechanics. Thermodynamics will average quantum mechanical properties over a large number of atoms and provide mathematical relationships between QM and measurable properties.</p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/#postulates-of-qm","title":"Postulates of QM","text":"<ol> <li> <p>State Function: The state of a system is described by a wavefunction \\(\\Psi(\\vec{r},t)\\) that depends on position and time.</p> </li> <li> <p>Observables: To every classical observable, there corresponds a linear, Hermitian operator \\(\\hat{A}\\). The expectation value obeys \\(\\int f^* (\\hat{A} g) \\, d\\tau = \\int g^* (\\hat{A} f) \\, d\\tau\\)</p> </li> <li> <p>Measurement: A measurement of \\(\\hat{A}\\) yields an eigenvalue \\(a\\):\\(\\hat{A} \\Psi = a \\Psi\\)</p> </li> <li> <p>Expectation Value: If \\(\\Psi\\) is normalized, \\(\\langle \\hat{A} \\rangle = \\int \\Psi^* \\hat{A} \\Psi \\, d\\tau\\)</p> </li> </ol> <p>Example: position \\(\\langle \\hat{x} \\rangle = \\int \\Psi^* x \\Psi \\, d\\tau\\)</p> <ol> <li>Time Evolution: The wavefunction evolves according to the time-dependent Schr\u00f6dinger equation: \\(i \\hbar \\frac{\\partial \\Psi}{\\partial t} = \\hat{H} \\Psi\\)</li> </ol>"},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/#working-with-the-hamiltonian-operator","title":"Working with the Hamiltonian Operator","text":"<p>The one-dimensional Hamiltonian:</p> \\[\\hat{H}(x) = -\\frac{\\hbar^2}{2m} \\frac{d^2}{dx^2} + V(x)\\] <p>where the first term is the kinetic energy operator and the second is the potential energy operator.</p> <p>We assume separation of variables:</p> \\[\\Psi(x,t) = \\psi(x) f(t)\\] <p>Plugging into the time-dependent Schr\u00f6dinger equation:</p> \\[i \\hbar \\frac{d}{dt} [f(t) \\psi(x)] = \\hat{H} [f(t) \\psi(x)]\\] <p>Recognizing that \\(f(t)\\) has no spatial dependence and \\(\\psi(x)\\) has no time dependence:</p> \\[i \\hbar \\frac{df}{dt} \\psi(x) = f(t) \\hat{H} \\psi(x)\\] <p>Divide both sides by \\(f(t)\\psi(x)\\):</p> \\[\\frac{i \\hbar}{f(t)} \\frac{df}{dt} = \\frac{\\hat{H} \\psi}{\\psi} = E\\] <p>where \\(E\\) is a separation constant (the total energy). This yields two separate equations:</p> <ol> <li>Time-Dependent Equation:</li> </ol> \\[i \\hbar \\frac{df}{dt} = E f(t) \\quad \\implies \\quad f(t) = A e^{-i E t / \\hbar}\\] <ol> <li>Time-Independent Schr\u00f6dinger Equation:</li> </ol> \\[\\hat{H} \\psi(x) = E \\psi(x)\\] <p>Full solution:</p> \\[\\Psi(x,t) = \\psi(x) e^{-i E t / \\hbar}\\]"},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/#born-interpretation-of-the-wavefunction","title":"Born Interpretation of the Wavefunction","text":"<ul> <li>\\(|\\psi(x)|^2\\) is the probability density, giving the probability of finding a particle between \\(x\\) and \\(x + dx\\):</li> </ul> \\[P(x) dx = |\\psi(x)|^2 dx\\] <ul> <li>Stationary States: The probability density is time-independent:</li> </ul> \\[|\\Psi(x,t)|^2 = |\\psi(x)|^2\\] <ul> <li>Time-Dependent Solutions (general):</li> </ul> \\[\\Psi(x,t) = \\hat{T} \\exp\\left(-\\frac{i}{\\hbar} \\int_0^t \\hat{H}(\\vec{r},t') dt' \\right) \\Psi(0)\\]"},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/#dirac-notation","title":"Dirac Notation","text":"<ul> <li>Bra: \\(\\langle \\psi | = \\psi^*\\)</li> <li>Ket: \\(|\\psi\\rangle = \\psi\\)</li> <li>Matrix Element:</li> </ul> \\[\\langle \\psi_i | \\hat{A} | \\psi_j \\rangle = \\int \\psi_i^* \\hat{A} \\psi_j \\, d\\tau\\] <ul> <li>Kronecker Delta:</li> </ul> \\[\\langle i | j \\rangle = \\delta_{ij} =  \\begin{cases} 1 &amp; i = j \\\\ 0 &amp; i \\neq j \\end{cases}\\] <p>Wavefunctions must be continuous, single-valued, and have continuous first derivatives. They must be quadratically integrable (\\(\\langle \\psi | \\psi \\rangle\\) exists), except in the case of unbounded free particles.</p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/#example-permutation-operator","title":"Example: Permutation Operator","text":"<p>The perumtation operator is: \\(\\hat{P}_{ij}\\)</p> \\[\\hat{P}_{ij}^2 = 1, \\quad \\hat{P}_{12} f = c f\\] <p>Applying the operator twice:</p> \\[\\hat{P}_{12} \\hat{P}_{12} f = \\hat{P}_{12} (c f) = c^2 f = f \\implies c = \\pm 1\\]"},{"location":"Statistical_Mechanics/lectures/Stat_01_20_26/#pauli-principle","title":"Pauli Principle","text":"<ul> <li>Fermions (half-integer spin): The total wavefunction must be antisymmetric under particle exchange.</li> <li>Bosons (integer spin): The total wavefunction must be symmetric under particle exchange.</li> </ul> <p>Example: For electrons, the total wavefunction must be antisymmetric with respect to the exchange of any two electrons.</p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_22_26/","title":"Lecture 2","text":""},{"location":"Statistical_Mechanics/lectures/Stat_01_22_26/#continuation-of-review-of-quantum-mechanics","title":"Continuation of Review of Quantum Mechanics","text":""},{"location":"Statistical_Mechanics/lectures/Stat_01_22_26/#non-interacting-particles","title":"Non-interacting Particles","text":"<p>A system of two noninteracting particles can be described by the equation \\(\\hat{H}_{total} \\Psi_{total} = E_{total} \\Psi_{total}\\) , where the total Hamiltonian is the sum of the individual Hamiltonians: $$ \\hat{H} = \\sum_{i=1}^{N} \\hat{H}_i = \\hat{H}_1 + \\hat{H}_2 + \\ldots + \\hat{H}_N $$</p> \\[ \\Psi_{total} = \\prod_{i=1}^{N} \\psi_i = \\psi_1 \\psi_2 \\ldots \\psi_N \\] <p>if we plug these back into the schrodinger equation, we get:</p> \\[ (H_1 + H_2) \\psi_1 \\psi_2 = E_{total} \\psi_1 \\psi_2 \\] <p>where we can see that \\(H_1\\) will be multiplied by both \\(\\psi_1\\) and \\(\\psi_2\\), but \\(H_1\\) only interacts with \\(\\psi_1\\), so we can bring the non-interacting \\(\\psi\\) out of the operator</p> \\[ \\psi_2 H_1 \\psi_1 + \\psi_1 H_2 \\psi_2 = E_{total} \\psi_1 \\psi_2 \\] <p>dividng both sides by \\(\\psi_1 \\psi_2\\) gives:</p> \\[ \\frac{H_1 \\psi_1}{\\psi_1} + \\frac{H_2 \\psi_2}{\\psi_2} = E_{total} \\] <p>This shows that the total energy is just the sum of individual energies and the total shrodinger equation is the sum of the two individual shrodiger equations:</p> \\[ H_1 \\psi_1 = E_1 \\psi_1 \\] \\[   H_2 \\psi_2 = E_2 \\psi_2 \\] <p>We have effectivly reduced 1 noninteracting, two-particle equation into 2, one-particle equations. We can then get energies and wavefunctions by solving the individual eigenvalue problems and taking the sum/product of the results to get the total energy/wavefunction.</p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_22_26/#quantum-mechanics-mechanical-modes","title":"Quantum Mechanics: Mechanical Modes","text":"<p>Particle in a box:</p> \\[ \\hat{H} = \\frac{-\\hbar^2}{2m} \\frac{d}{dx} \\] <p>with energies:</p> <p>$$ E_n = \\frac{\\hbar^2 n^2}{8 m a^2}  $$ with n = 1,2,3,... but not 0.</p> <p>Harmonic Oscillator:</p> \\[ \\hat{H} = \\frac{-\\hbar^2}{2m} \\frac{d^2}{dx^2} + \\frac{1}{2} kx^2 \\] <p>with energies:</p> \\[ E_n = (n + \\frac{1}{2})\\hbar \\omega  \\] <p>with n = 0,1,2,3,... and \\(\\omega = \\sqrt{\\frac{k}{m}}\\).</p> <p>Rigid Rotor:</p> \\[ \\hat{H} = \\frac{-\\hbar^2}{2 I} (\\frac{1}{\\sin{\\theta}} \\frac{d}{d\\theta}(\\sin{\\theta}\\frac{d}{d\\theta}) + \\frac{1}{\\sin^2{\\theta}}\\frac{d^2}{d\\phi^2}) \\] <p>with energies:</p> \\[ E_j = \\frac{J(J+1)\\hbar^2}{2I} \\] <p>where J = 0,1,2,3,... and \\(I = \\mu d^2\\) is the moment of intertia. </p> <p>Degeneracy: In the rigid rotor example, energy depends on J but \\(\\psi\\) depends on both J and m (where m is the z component of angular momentum). Degenerate states are states with the same energy resulting from different quantum numbers. For a given J, m can take on values from -J to +J, resulting in a degeneracy of (2J + 1) for each energy level.</p> <p>As particle # and model complexity increase, degeneracy becomes much more common. </p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_22_26/#correspondence-principle","title":"Correspondence Principle","text":"<p>As quantum numbers increase, quantum mechanical results converge to the classical mechanic expectations. For example, in the particle in a box model, as n becomes very large, the energy levels become very closely spaced, and the behavior of the particle approaches that of a classical particle moving freely within the box.</p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_22_26/#review-of-thermodynamics","title":"Review of Thermodynamics:","text":"<p>System: the part of the unverse under consideration Surrondings: the part of the universe out of the boundary</p> <p>Heat can be exchanged between the ststem and surroinds or surroundsing may do wokr on the system (and vis versa)</p> <p>Kinds of systems: - Isolated: No exchange of energy or matter - Closed: Exchange of energy but not matter - Open: Exchange of both energy and matter</p> <p>to describe the state of a system, we need to know (for example) V, P, T, m, or amount of substance n.</p> <p>Extensive Properties: depend on the amount of substance (V, m, n) Intensive Properties: do not depend on the amount of substance (P, T, density)</p> <p>We can combine extensive properties to get intensive properties (density = m/V, molar volume = V/n)</p> <p>Equilbrium is said to be a \"defintae state\" with no fluctuations in macroscopic properties over time.</p> <p>Many properties that we care about are \"state\" varibles which do not depend on the path taken to reach the state and therefore are not defined by their histroy. </p> <p>We can define the state of a system using state variables such as P, V, T, and n.</p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_22_26/#laws-of-thermodynamics","title":"Laws of Thermodynamics","text":"<ul> <li>Zeroth Law: If system A is in thermal equilibrium with system B, and system B is in thermal equilibrium with system C, then system A is in thermal equilibrium with system C.</li> <li>First Law: work is done to achieve motion agaisnt an opposing force. Energy is the capacity to do work. Energy can be tranfered with heat when the energy change is a result of a temperature change. </li> </ul> \\[ \\Delta U = q + w \\] <p>$$ dU = \\not{d} q + \\not{d} w $$ where the bar through the d indicates inexact differential, meaning that q and w are path functions and not state functions. U is a state function.</p> <p>The total internal energy of an isolated system is constant. In a closed system dU &gt;0 is energy gained In a closed system dU &lt;0 is energy lost</p> <p>State functions depend only on the current state of the system and not the path. </p> \\[ \\int_a^b dU = U_b - U_a = \\Delta U \\] <p>Because state function ar path independent, differentias are exact.  q and w are path functions adn thier differentials are inexact.</p> <p>Eulers test for exact differentials: For a function f(x,y) with differential df = M dx + N dy, if  $$ \\frac{\\partial M}{\\partial y} = \\frac{\\partial N}{\\partial x} $$ then df is an exact differential.</p> <ul> <li>Second Law: In any spontaneous process, the total entropy of a system and its surroundings always increases. For a reversible process, the total entropy remains constant.<ul> <li>dS &gt; dq/T : Proscess is spontaneous and reversivble </li> <li>dS = dq/T : Process is reversible (equilibrium)</li> <li>dS &lt; dq/T : Not possible In an isolated system dq = 0 and we get \\(\\delta S &gt;0\\)</li> </ul> </li> </ul> <p>The Fundamental Equation</p> \\[ dU = T dS - P dV + \\mu dn \\] <p>This equation involves only exact differentials so it can be used at both euqilibrum and non-equilibrium states. </p> \\[ dS = \\frac{dU}{T} + \\frac{PdV}{T} \\] <ul> <li>Third Law: The entropy of a perfect crystal at absolute zero is exactly zero. As temperature approaches absolute zero, the entropy of a system approaches a constant minimum.</li> </ul> <p>If S&gt;0 at T=0K, then there is residual entropy from disorder in the system. </p>"},{"location":"Statistical_Mechanics/lectures/Stat_01_22_26/#enthalpy-as-an-example","title":"Enthalpy as an Example:","text":"<p>Entropy provides a criterion ofr spontaneity but it does not allow for calculations at constant T and V or T and P.</p> <p>Internal energy \\(\\Delta U = q + w\\) can be re-written as: \\(\\Delta U = q_p - PV\\) which can futher be rearranged to \\(\\Delta U + P \\Delta V = q_p\\)</p> <p>\\(\\Delta U\\) and \\(\\Delta V\\) are state varibles so they can be written as differneces (e.g. \\(U_2 - U_1\\)). Using this form we can recast our equation to the form:</p> \\[ U_2 - U1 + P(V_2 - V_1) = q_p = (U_2 + PV_2) - (U_1 + PV_1) \\] <p>It is now useful to define a quantity (Enthalpy) as</p> \\[ H = U + PV \\] <p>This is a legendre transform in disguise where we took U and transformed it to H</p> <p>\\(dH = dU + VdP + PdV\\) \\(dU = dH - VdP - PdV\\) Here we can recall the fundamental equation \\(dU = Tds-PdV\\) and write</p> <p>$$ dH = TdS + VdP $$ where s and p are siad to be the \"natural variables\" of enthalpy. </p> <p>Other thermodynamic potentials include:</p> <p>Helmholtz Energy: A = U - TS which is the legendre transform of \\(dA = -PdV - SdT\\)</p> <p>Gibbs Free Energy: G = H- TS is the legendre transform of \\(dG = VdP - SdT\\)</p> <p>Why are natural variables important? - They are can be held constant to determine spontaneity - We can derive useful relations from them - If we know the a thermodynamic potential in terms of its natural variables, we can calculate all other variables and potentials. </p> <p>Example Say we know Gibbs free energy, G, in terms of its natural variables (P and T), then we can solve for the exact differential for U:</p> \\[ dU = (\\frac{\\partial U}{\\partial S})_V dS + (\\frac{\\partial U}{\\partial V})_s dV  \\] <p>we can compare this to \\(dU = TdS -PdV\\) and our knowledge of exact differentials to see that \\(T = (\\frac{\\partial U}{\\partial S})_v\\) and \\(-P = (\\frac{\\partial U}{\\partial V})_s\\)</p> <p>Analogous procedures can be followed to obtain: | \\(T = (\\frac{\\partial H}{\\partial S})_p\\) | \\(-S = (\\frac{\\partial A}{\\partial T})_V\\) | \\(-S = (\\frac{\\partial G}{\\partial T})_p\\) |</p> <p>| \\(V = (\\frac{\\partial H}{\\partial P})_s\\) | \\(-P = (\\frac{\\partial A}{\\partial V})_T\\) | \\(V = (\\frac{\\partial G}{\\partial P})_T\\) |</p> <p>One reason we said natural variables are importat is that we can derive useful relations, the so-called \"maxwell relations\"</p> <p>From U: $$(\\frac{\\partial T}{\\partial V})_S = -(\\frac{\\partial P}{\\partial S})_V $$</p> <p>From H</p> \\[ (\\frac{\\partial T}{\\partial P})_S = (\\frac{\\partial V}{\\partial S})_P \\] <p>From A:</p> \\[ (\\frac{\\partial P}{\\partial T})_V = (\\frac{\\partial S}{\\partial V})_T \\] <p>From G:</p> \\[ (\\frac{\\partial V}{\\partial T})_P = -(\\frac{\\partial S}{\\partial P})_T \\] <p>In open systems we must account for \"N\" different species where \\(n_i\\) is the amount of species i in the system. </p> <p>The differential for U now becomes </p> \\[ dU = (\\frac{\\partial U}{\\partial S})_{Vn n_i} dS + (\\frac{\\partial U}{\\partial V})_{S, n_i} dV + \\sum_{i=1}^N (\\frac{\\partial U}{\\partial n_i}),_{S, V, n_j} dn_i \\] \\[ dU = TdS - PdV + \\sum_{i=1}^N \\mu_i dn_i \\] <p>where \\(\\mu_i\\) is the \"chemical potential defined as </p> \\[ \\mu_i = (\\frac{\\partial U}{\\partial n_i})_{S, v, nj} \\] \\[ \\mu_i = (\\frac{\\partial H}{\\partial n_i})_{S, P, nj} = (\\frac{\\partial A}{\\partial n_i})_{T, V, nj} = (\\frac{\\partial G}{\\partial n_i})_{T, P, nj} \\]"}]}